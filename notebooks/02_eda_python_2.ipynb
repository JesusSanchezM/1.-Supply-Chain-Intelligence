{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a10b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# =================================================================\n",
    "# SECTION 1: SETUP & ECONOMETRIC DEFLATION\n",
    "# =================================================================\n",
    "\n",
    "# 1.1 Path Setup\n",
    "CURRENT_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(CURRENT_DIR, '..'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# 1.2 Import Logic from src\n",
    "from src.feature_engineering import (\n",
    "    add_time_features, calculate_rfm_metrics, \n",
    "    prepare_rfm_for_clustering, perform_abc_analysis\n",
    ")\n",
    "\n",
    "# 1.3 Data Loading & Initial Prep\n",
    "PROCESSED_PATH = r\"C:\\Users\\Jesus Sanchez\\Desktop\\ALEXIS\\1. Pre-Trabajo\\1. Supply Chain Intelligence\\data\\processed\\cleaned_retail_data.csv\"\n",
    "df_raw = pd.read_csv(PROCESSED_PATH, parse_dates=['InvoiceDate'])\n",
    "\n",
    "if 'TotalSum' not in df_raw.columns:\n",
    "    df_raw['TotalSum'] = df_raw['Quantity'] * df_raw['Price']\n",
    "\n",
    "df_raw['Year'] = df_raw['InvoiceDate'].dt.year\n",
    "\n",
    "# 1.4 Inflation Adjustment (Deflating 2011 to 2010 Constant Prices)\n",
    "INFLATION_2011 = 0.039  # 3.9%\n",
    "df_2010 = df_raw[df_raw['Year'] == 2010].copy()\n",
    "df_2011 = df_raw[df_raw['Year'] == 2011].copy()\n",
    "\n",
    "print(f\"ğŸ“‰ Deflating 2011 values (Inflation: {INFLATION_2011*100}%)...\")\n",
    "df_2011['TotalSum'] = df_2011['TotalSum'] / (1 + INFLATION_2011)\n",
    "df_2011['Price'] = df_2011['Price'] / (1 + INFLATION_2011)\n",
    "\n",
    "# Apply Time Features\n",
    "df_2010 = add_time_features(df_2010)\n",
    "df_2011 = add_time_features(df_2011)\n",
    "\n",
    "# =================================================================\n",
    "# SECTION 2: LOGISTICS WORKLOAD (BAR CHARTS)\n",
    "# =================================================================\n",
    "\n",
    "print(\"ğŸ“Š Generating Comparative Logistics Bar Charts...\")\n",
    "DAYS_ORDER = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "for i, (year_df, yr, color) in enumerate([(df_2010, 2010, 'Blues_d'), (df_2011, 2011, 'Oranges_d')]):\n",
    "    sns.countplot(data=year_df, x='DayName', order=DAYS_ORDER, palette=color, ax=axes[0, i])\n",
    "    axes[0, i].set_title(f'Logistics Volume by Day: {yr}', fontweight='bold')\n",
    "    sns.countplot(data=year_df, x='Hour', palette=color, ax=axes[1, i])\n",
    "    axes[1, i].set_title(f'Hourly Operational Peaks: {yr}', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =================================================================\n",
    "# SECTION 3: RFM & AI CLUSTERING (K=4)\n",
    "# =================================================================\n",
    "\n",
    "def process_year_intelligence(df_year):\n",
    "    rfm_year = calculate_rfm_metrics(df_year)\n",
    "    scaled_data, rfm_scaler = prepare_rfm_for_clustering(rfm_year)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=4, init='k-means++', random_state=42, n_init=10)\n",
    "    rfm_year['Cluster_ID'] = kmeans.fit_predict(scaled_data)\n",
    "    \n",
    "    # Manual Labeling\n",
    "    rfm_year['R_Score'] = pd.qcut(rfm_year['Recency'], 5, labels=[5, 4, 3, 2, 1]).astype(int)\n",
    "    rfm_year['F_Score'] = pd.qcut(rfm_year['Frequency'].rank(method='first'), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    rfm_year['M_Score'] = pd.qcut(rfm_year['Monetary'], 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    \n",
    "    def assign_segment(row):\n",
    "        r, f, m = row['R_Score'], row['F_Score'], row['M_Score']\n",
    "        if r >= 4 and f >= 4 and m >= 4: return 'Champions (VIP)'\n",
    "        elif m >= 4 and r >= 3: return 'Big Spenders'\n",
    "        elif r <= 2: return 'At Risk / Hibernating'\n",
    "        else: return 'Core Customers'\n",
    "    \n",
    "    rfm_year['Segment'] = rfm_year.apply(assign_segment, axis=1)\n",
    "    return rfm_year, scaled_data, rfm_scaler, kmeans\n",
    "\n",
    "rfm_2010, scaled_2010, _, _ = process_year_intelligence(df_2010)\n",
    "rfm_2011, scaled_2011, scaler_2011, model_2011 = process_year_intelligence(df_2011)\n",
    "\n",
    "# 3.1 Side-by-Side 3D Visuals\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "for i, (scaled, rfm_y, yr) in enumerate([(scaled_2010, rfm_2010, 2010), (scaled_2011, rfm_2011, 2011)]):\n",
    "    ax = fig.add_subplot(1, 2, i+1, projection='3d')\n",
    "    ax.scatter(scaled['Recency'], scaled['Frequency'], scaled['Monetary'], \n",
    "               c=rfm_y['Cluster_ID'], cmap='viridis', s=40, alpha=0.6)\n",
    "    ax.set_title(f'3D Cluster Structure: {yr} (Constant Prices)', fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "# =================================================================\n",
    "# SECTION 4: IMPACT SUMMARY (CONSTANT Â£)\n",
    "# =================================================================\n",
    "\n",
    "def run_economic_impact(df_year, rfm_year):\n",
    "    abc_res = perform_abc_analysis(df_year)\n",
    "    sku_map = abc_res.set_index('Description')['ABC_Class'].to_dict()\n",
    "    df_year['ABC_Class'] = df_year['Description'].map(sku_map)\n",
    "    \n",
    "    wealth = rfm_year.groupby('Segment')['Monetary'].sum().reset_index()\n",
    "    wealth['Revenue_%'] = (wealth['Monetary'] / wealth['Monetary'].sum()) * 100\n",
    "    wealth = wealth.sort_values(by='Revenue_%', ascending=False)\n",
    "    return wealth, df_year\n",
    "\n",
    "wealth_2010, df_2010 = run_economic_impact(df_2010, rfm_2010)\n",
    "wealth_2011, df_2011 = run_economic_impact(df_2011, rfm_2011)\n",
    "\n",
    "print(\"\\nğŸ’° --- IMPACT SUMMARY 2010 ---\")\n",
    "display(wealth_2010.style.format({'Monetary': 'Â£{:,.2f}', 'Revenue_%': '{:.1f}%'}))\n",
    "print(\"\\nğŸ’° --- IMPACT SUMMARY 2011 (Constant 2010 Prices) ---\")\n",
    "display(wealth_2011.style.format({'Monetary': 'Â£{:,.2f}', 'Revenue_%': '{:.1f}%'}))\n",
    "\n",
    "# =================================================================\n",
    "# SECTION 5: ROOT CAUSE & PERSISTENCE\n",
    "# =================================================================\n",
    "\n",
    "df_en_2010 = df_2010.merge(rfm_2010[['Segment']], left_on='Customer ID', right_index=True, how='left')\n",
    "df_en_2011 = df_2011.merge(rfm_2011[['Segment']], left_on='Customer ID', right_index=True, how='left')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(22, 7), sharey=True)\n",
    "order = ['Champions (VIP)', 'Big Spenders', 'Core Customers', 'At Risk / Hibernating']\n",
    "\n",
    "for i, (df_en, yr) in enumerate([(df_en_2010, 2010), (df_en_2011, 2011)]):\n",
    "    pd.crosstab(df_en['Segment'], df_en['ABC_Class'], normalize='index').reindex(order).plot(\n",
    "        kind='bar', stacked=True, color=['#27AE60', '#F1C40F', '#E74C3C'], ax=axes[i], edgecolor='black'\n",
    "    )\n",
    "    axes[i].set_title(f'Inventory Dependency Root Cause: {yr}', fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "# Persistence\n",
    "models_path = '../models'\n",
    "if not os.path.exists(models_path): os.makedirs(models_path)\n",
    "joblib.dump(model_2011, os.path.join(models_path, 'rfm_kmeans_2011.pkl'))\n",
    "joblib.dump(scaler_2011, os.path.join(models_path, 'rfm_scaler_2011.pkl'))\n",
    "\n",
    "print(f\"âœ… Side-by-Side Analysis Complete. Values adjusted for inflation.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
